# final-project-team12

# Members
### William Han, Matthew Jung, Daun Kim, Christopher Soong

# Topic
### Ability of doctors and AI to detect Deepfake tampering in medical data.

# Data Analysis 
### Mission
Team 12 focuses on tackling the problem and possibility of cyber-attacks in hospitals for their confidential data, such as medical images. Our dataset consists of lung CT scans that have been tampered with by removing or injecting fake cancers into the images. These images were labeled True-Benign (TB), True-Malicious (TM), False-Benign (FB), and False-Malicious (FM). TB, TM, FB, and FM respectively means no cancer, real cancer, real cancer but was removed, and fake cancer but was injected. 
### Purpose
 Team 12 breaks the data down by looking at the csv files of blind and open trials that has a state-of-the-art artificial intelligence program and several medical professionals carefully observe these images and diagnose them. The accuracy of diagnosis in respect to each image type is visualized by counting the observations and creating proportions. Team 12 also seeks the extent of influence that open/blind trials have on the AI program and doctor’s accuracy in correctly classifying cancer in the images. Open trials meant that the doctor’s knew of the tampered images and blind trials were when they did not know this fact. Finally, Team 12 analyzes whether a human doctor’s confidence has any impact on their ability to diagnose precisely. 
### Results 
We found that the doctor’s had higher accuracy in finding cancers compared to the artificial intelligence program.  Additionally, the accuracy of diagnosis in open trial was greater than the blind trial. Finally, the doctor’s confidence and the rate of misdiagnosis are positively correlated.



