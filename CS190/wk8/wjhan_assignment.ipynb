{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHuBcWkh-A2F"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will create a model for segmentation of tumor from abdominal CT images using custom loss function modifications to increase prediction sensitivity.\n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw94HIOL-A2H"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook\n",
        "* final trained `*.hdf5` model file\n",
        "* final compiled `*.csv` file with performance statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BsZnnsi-A2H"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHcM5Exy-A2I"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJudwd58-A2I"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OocufS_Y-A2I",
        "outputId": "a22d72b1-4f71-4354-cf18-bdb981b0b08f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jarvis-md\n",
            "  Downloading jarvis_md-0.0.1a17-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▋                            | 10 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 40 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n",
            "Collecting pyyaml>=5.2\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->jarvis-md) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->jarvis-md) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2022.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a17 pyyaml-6.0\n"
          ]
        }
      ],
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRY3Dibm-A2J"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fty11oAw-A2J"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model, models, losses, layers, optimizers\n",
        "from jarvis.train import datasets\n",
        "from jarvis.utils.display import imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq7CmDo6-A2K"
      },
      "source": [
        "# Data\n",
        "\n",
        "The data used in this tutorial will consist of kidney tumor CT exams derived from the Kidney Tumor Segmentation Challenge (KiTS). More information about he KiTS Challenge can be found here: https://kits21.kits-challenge.org/. In this exercise, we will use this dataset to derive a model for slice-by-slice kidney segmentation. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/ct_kits`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B1_RV0YF-A2K",
        "outputId": "b944ed76-b5ed-4720-c46a-55c83713073e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-05-21 18:57:53 ] [====================] 100.000% : Extracting archive (0000818 / 0000818) "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'code': '/data/raw/ct_kits', 'data': '/data/raw/ct_kits'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='ct/kits')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw-LxHor-A2K"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fXAsQUE-A2K"
      },
      "source": [
        "### Stratified Sampling\n",
        "\n",
        "Use the following code block to define a custom configuration dictionary to increase the sampling distribution of tumor (`lbl-crp-02`) up to 30%:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aJ6jLhpj-A2L"
      },
      "outputs": [],
      "source": [
        "# --- Configs dict to implement stratified sampling\n",
        "configs = {\n",
        "    'batch': {'size': 16},\n",
        "    'sampling': {\n",
        "        'lbl-crp-00': 0.4,\n",
        "        'lbl-crp-01': 0.3,\n",
        "        'lbl-crp-02': 0.3}}\n",
        "\n",
        "# --- Prepare generators\n",
        "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='2d', configs=configs, custom_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JckFZ37-A2L"
      },
      "source": [
        "In the assignment, feel free to experiment with different stratified sampling distributions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVqmRpzr-A2L"
      },
      "source": [
        "### Define the backbone model\n",
        "\n",
        "Use the following cell block to define your backbone for the semantic segmentation task:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lambda and kwargs\n",
        "\n",
        "kwargs = {\n",
        "    'kernel_size': (1, 3, 3),\n",
        "    'padding': 'same'}\n",
        "\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2))))"
      ],
      "metadata": {
        "id": "srxAutLq_CHp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4dQZCOvY-A2L"
      },
      "outputs": [],
      "source": [
        "# --- Define input\n",
        "x = Input(shape=(None, 96, 96, 1), dtype='float32')\n",
        "\n",
        "# --- Define model\n",
        "l1 = conv1(8, x)\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "\n",
        "l6  = tran2(48, l5)\n",
        "l7  = tran2(32, conv1(48, concat(l4, l6)))\n",
        "l8  = tran2(16, conv1(32, concat(l3, l7)))\n",
        "l9  = tran2(8,  conv1(16, concat(l2, l8)))\n",
        "l10 = conv1(8,  l9)\n",
        "# --- Define logits\n",
        "logits = layers.Conv3D(filters=2, **kwargs)(l10)\n",
        "\n",
        "\n",
        "# --- Create model\n",
        "backbone = Model(inputs=x, outputs=logits) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzMK-lLV-A2L"
      },
      "source": [
        "### Define training model\n",
        "\n",
        "Use the following cell block to start building your training model using the backbone network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "63tbKwNk-A2L"
      },
      "outputs": [],
      "source": [
        "# --- Define inputs\n",
        "inputs = {\n",
        "    'dat': Input(shape=(None, 96, 96, 1), dtype='float32'),\n",
        "    'lbl': Input(shape=(None, 96, 96, 1), dtype='uint8')}\n",
        "# --- Define model\n",
        "logits = backbone(inputs['dat'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jseUFA9x-A2L"
      },
      "source": [
        "### Custom loss function\n",
        "\n",
        "In order to create a high sensitivity classifier for tumor segmentation, a combined weighted and masked loss strategy should be implemented. More specifically, the following weighting tensor should be create:\n",
        "\n",
        "* class 0 (background; non-kidney): set `wgt` to 0\n",
        "* class 1 (background; kidney): set `wgt` to 1\n",
        "* class 2 (foreground; tumor): set `wgt` to positive value\n",
        "\n",
        "In addition, recall that you will need to convert the three-class ground-truth label into a binarized target label (tumor or no tumor)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#functions\n",
        "\n",
        "def create_weights(lbl, pos_weight=5.0):\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "i8DD3JPZ_VEm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UT2LSFNg-A2M"
      },
      "outputs": [],
      "source": [
        "# --- Create weights\n",
        "wgt = create_weights(inputs['lbl'])\n",
        "# --- Create y_true (binarized ground-truth)\n",
        "y_true = tf.cast(inputs['lbl'] == 2, dtype='uint8')\n",
        "# --- Create loss\n",
        "sce = losses.SparseCategoricalCrossentropy(from_logits=True)(\n",
        "    y_true=y_true,\n",
        "    y_pred=logits,\n",
        "    sample_weight=wgt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKRzlAal-A2M"
      },
      "source": [
        "### Custom metrics\n",
        "\n",
        "The goal of weighted and/or masked loss functions in this example is maximize the sensitivity for tumor prediction. Thus, in addition to a standard Dice score metric, we will additionally use foreground sensitivity to track overall model performance. Recall that to adjust the metrics to account for a custom weighted loss function, one must simply ignore predictions from masked regions (e.g., the model is required to predict accurate results in these regions). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9XryDduQ-A2M"
      },
      "outputs": [],
      "source": [
        "def calculate_dsc(y_true, y_pred, weights=None, c=1):\n",
        "    \"\"\"\n",
        "    Method to calculate the Dice score coefficient for given class\n",
        "    \n",
        "    :params\n",
        "    \n",
        "      y_true : ground-truth label\n",
        "      y_pred : predicted logits scores\n",
        "           c : class to calculate DSC on\n",
        "    \n",
        "    \"\"\"  \n",
        "    true = y_true[..., 0] == c\n",
        "    pred = tf.math.argmax(y_pred, axis=-1) == c \n",
        "    \n",
        "    if weights is not None:\n",
        "        true = true & (weights[..., 0] != 0)\n",
        "        pred = pred & (weights[..., 0] != 0)\n",
        "\n",
        "    A = tf.math.count_nonzero(true & pred) * 2\n",
        "    B = tf.math.count_nonzero(true) + tf.math.count_nonzero(pred)\n",
        "    \n",
        "    return tf.math.divide_no_nan(\n",
        "        tf.cast(A, tf.float32), \n",
        "        tf.cast(B, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HAyHijNK-A2M"
      },
      "outputs": [],
      "source": [
        "def calculate_sen(y_true, y_pred, weights=None, c=1, **kwargs):\n",
        "    \"\"\"\n",
        "    Method to implement sensitivity (recall) on raw cross-entropy logits\n",
        "\n",
        "    \"\"\"\n",
        "    true = y_true[..., 0] == c\n",
        "    pred = tf.math.argmax(y_pred, axis=-1) == c \n",
        "    \n",
        "    if weights is not None:\n",
        "        true = true & (weights[..., 0] != 0)\n",
        "        pred = pred & (weights[..., 0] != 0)\n",
        "        \n",
        "    tp = true & pred\n",
        "\n",
        "    num = tf.math.count_nonzero(tp) \n",
        "    den = tf.math.count_nonzero(y_true)\n",
        "\n",
        "    num = tf.cast(num, tf.float32)\n",
        "    den = tf.cast(den, tf.float32)\n",
        "\n",
        "    return tf.math.divide_no_nan(num, den)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q9ElovTJ-A2M"
      },
      "outputs": [],
      "source": [
        "# --- Create metrics\n",
        "dsc = calculate_dsc(y_true, logits, wgt)\n",
        "sen = calculate_sen(y_true, logits, wgt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk-S_VPf-A2M"
      },
      "source": [
        "Now, we are ready to create the `training` model and add the corresponding loss and accuracy tensors. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iXL7x-jV-A2M"
      },
      "outputs": [],
      "source": [
        "# --- Create model\n",
        "training = Model(inputs=inputs, outputs={'logits': logits, 'dsc': dsc, 'sen': sen})\n",
        "# --- Add loss\n",
        "training.add_loss(sce)\n",
        "\n",
        "# --- Add metrics\n",
        "training.add_metric(dsc, name='dsc')\n",
        "training.add_metric(sen, name='sen')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJr2UH3U-A2M"
      },
      "source": [
        "### Compile the model\n",
        "\n",
        "Use the following cell block to compile your model with an appropriate optimizer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hBrgWqFA-A2M"
      },
      "outputs": [],
      "source": [
        "optimizer = optimizers.Adam(learning_rate=2e-4)\n",
        "\n",
        "training.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOVqp815-A2M"
      },
      "source": [
        "### In-memory data\n",
        "\n",
        "To speed up training, consider loading all your model data into RAM memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uYaBmyX2-A2N",
        "outputId": "13276a7c-4ee4-4633-d779-236f9b178023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-05-21 19:02:01 ] [====================] 100.000% : Iterating | 000402    "
          ]
        }
      ],
      "source": [
        "# --- Load data into memory for faster training\n",
        "client.load_data_in_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xokO4Ti-A2N"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Use the following cell block to train your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LeBS82R2-A2N",
        "outputId": "124c360d-59eb-4297-9a22-7096c9d5e462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 20s 23ms/step - loss: 0.6220 - dsc: 0.0406 - sen: 0.3127\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.2796 - dsc: 0.0102 - sen: 0.0119\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.1567 - dsc: 0.0490 - sen: 0.0262\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.1043 - dsc: 0.0862 - sen: 0.0466\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 5s 50ms/step - loss: 0.0785 - dsc: 0.1513 - sen: 0.0864 - val_loss: 0.0746 - val_dsc: 0.0498 - val_sen: 0.0259\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0652 - dsc: 0.2816 - sen: 0.1804\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0560 - dsc: 0.5457 - sen: 0.4405\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.0504 - dsc: 0.6328 - sen: 0.5645\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.0428 - dsc: 0.6683 - sen: 0.6374\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 0.0395 - dsc: 0.6887 - sen: 0.6488 - val_loss: 0.0370 - val_dsc: 0.7273 - val_sen: 0.7003\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0365 - dsc: 0.7168 - sen: 0.6882\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.0344 - dsc: 0.7163 - sen: 0.6910\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.0333 - dsc: 0.7446 - sen: 0.7132\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 2s 25ms/step - loss: 0.0296 - dsc: 0.7704 - sen: 0.7521\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 0.0277 - dsc: 0.7665 - sen: 0.7498 - val_loss: 0.0254 - val_dsc: 0.8108 - val_sen: 0.8481\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0237 - dsc: 0.7932 - sen: 0.7720\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0239 - dsc: 0.8072 - sen: 0.7952\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.0219 - dsc: 0.8141 - sen: 0.7986\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.0211 - dsc: 0.8113 - sen: 0.7933\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 4s 44ms/step - loss: 0.0203 - dsc: 0.8135 - sen: 0.8072 - val_loss: 0.0171 - val_dsc: 0.8525 - val_sen: 0.8021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f913785c1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "training.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=100, \n",
        "    epochs=20,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=100,\n",
        "    validation_freq=5,\n",
        "    use_multiprocessing=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ4PZ1pI-A2N"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to calculate model performance. The following metrics should be calculated:\n",
        "\n",
        "* pixel-wise sensitivity (mean, median, 25th percentile, 75th percentile)\n",
        "* Dice score coefficient (mean, median, 25th percentile, 75th percentile)\n",
        "\n",
        "### Performance\n",
        "\n",
        "The following minimum performance metrics must be met for full credit:\n",
        "\n",
        "* median pixel-wise sensitivity: >0.70\n",
        "* median Dice score coefficient: >0.70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mmk1SMi0-A2N"
      },
      "outputs": [],
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD8MQQ_6-A2N"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **validation** cohort sensitivity and Dice score statistics. There is no need to submit training performance accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aaTj6-fH-A2N",
        "outputId": "3f0e0338-51e8-4e74-e567-b771500e20f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-05-21 19:04:54 ] [====================] 100.000% : Iterating | 000402    "
          ]
        }
      ],
      "source": [
        "x, y = next(test_valid)\n",
        "outputs = training.predict(x)\n",
        "\n",
        "test_train, test_valid = client.create_generators(test=True)\n",
        "\n",
        "dice = []\n",
        "sens = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    if (x['lbl'] == 2).any():\n",
        "    \n",
        "        outputs = training.predict(x)\n",
        "\n",
        "        dice.append(outputs['dsc'])\n",
        "\n",
        "        sens.append(outputs['sen'])\n",
        "\n",
        "dice = np.array(dice)\n",
        "sens = np.array(sens)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['dice'] = dice\n",
        "df['sens'] = sens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('./wjhan_results.csv')"
      ],
      "metadata": {
        "id": "ObcKZZ2cAjI3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmLUncrr-A2N"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Q_hV7k5O-A2N",
        "outputId": "7c8aaf91-5192-4ce7-e88a-3794ed01a594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# --- Serialize a model\n",
        "backbone.save('./wjhan_model.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xzBvOMt-A2N"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}