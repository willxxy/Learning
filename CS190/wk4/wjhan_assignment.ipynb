{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZzC8Jewn8hg"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will train a convolutional neural network (CNN) to detect the normal kidney on a slice-by-slice basis from abdominal CT exams. \n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u52CHad4n8hj"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook\n",
        "* final trained `*.hdf5` model file\n",
        "* final compiled `*.csv` file with performance statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gri-08bsn8hk"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kud0gmF0n8hl"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spSH9NXun8hl"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW3jHRq7n8hl",
        "outputId": "9d9ee21b-8a36-4646-fc79-1c3175a74f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jarvis-md\n",
            "  Downloading jarvis_md-0.0.1a17-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▋                            | 10 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 81 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.3.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Collecting pyyaml>=5.2\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->jarvis-md) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->jarvis-md) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2022.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a17 pyyaml-6.0\n"
          ]
        }
      ],
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8VXK0vGn8hm"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ioQaFdeZn8hn"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd\n",
        "from tensorflow.keras import Input, Model, models, layers, losses, metrics, optimizers\n",
        "from jarvis.train import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Aq8xtFDn8hn"
      },
      "source": [
        "# Data\n",
        "\n",
        "The data used in this tutorial will consist of kidney tumor CT exams derived from the Kidney Tumor Segmentation Challenge (KiTS). More information about he KiTS Challenge can be found here: https://kits21.kits-challenge.org/. In this exercise, we will use this dataset to derive a model for slice-by-slice kidney detection. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/ct_kits`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. \n",
        "\n",
        "The following lines of code will:\n",
        "\n",
        "1. Download the dataset (if not already present) \n",
        "2. Prepare the necessary Python generators to iterate through dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22cHQMMMn8hn",
        "outputId": "359286bb-0598-4bc8-c223-c1b171a764ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-04-22 17:09:15 ] [====================] 100.000% : Extracting archive (0000418 / 0000418) "
          ]
        }
      ],
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='ct/kits-128')\n",
        "\n",
        "# --- Prepare generators and model inputs\n",
        "gen_train, gen_valid, client = datasets.prepare(name='ct/kits-128', keyword='128*glb')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIGK7nXbn8ho"
      },
      "source": [
        "# Training\n",
        "\n",
        "In this assignment we will train a basic convolutional neural network to predict the correct imaging series protocol on prostate MRI. At minumum you must include one of the following modern CNN architecture motifs techniques covered in the tutorial:\n",
        "\n",
        "* residual function (with preactivation blocks)\n",
        "* Inception module\n",
        "* squeeze-and-excitation module\n",
        "\n",
        "You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zZeJlIn8ho"
      },
      "source": [
        "### Define backbone model\n",
        "\n",
        "Feel free to use the `lambda` helper functions as demonstrated in the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    'kernel_size': (1, 3, 3),\n",
        "    'padding'    : 'same',\n",
        "    'kernel_initializer' : 'he_normal'\n",
        "}\n",
        "\n",
        "#lambda\n",
        "\n",
        "conv = lambda x, filters, strides: layers.Conv3D(filters = filters , strides = strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides = 1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides = (1, 2, 2))))"
      ],
      "metadata": {
        "id": "b1_n_VtiBkrd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def s_e(layer):\n",
        "\n",
        "  sqz = layers.AveragePooling3D((1, layer.shape[2], layer.shape[3]))(layer)\n",
        "  cha = int(layer.shape[-1]/4)\n",
        "  exc = layers.Conv3D(filters = cha, kernel_size = 1, activation = 'relu')(sqz)\n",
        "\n",
        "  sca = layers.Conv3D(filters = layer.shape[-1], kernel_size = 1, activation = 'sigmoid')(exc)\n",
        "  return layer * sca"
      ],
      "metadata": {
        "id": "ZKQo6X2BIWYh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3ROHPnGtn8ho"
      },
      "outputs": [],
      "source": [
        "# --- Define input\n",
        "x = Input(shape=(None, 128, 128, 1), dtype='float32')\n",
        "\n",
        "# --- Define model\n",
        "l1 = conv1(32,  x)\n",
        "l1 = s_e(l1)\n",
        "\n",
        "l2 = conv1(48,  conv2(48,  l1))\n",
        "l2 = s_e(l2)\n",
        "\n",
        "l3 = conv1(64,  conv2(64,  l2))\n",
        "l3 = s_e(l3)\n",
        "\n",
        "l4 = conv1(80,  conv2(80,  l3))\n",
        "l4 = s_e(l4)\n",
        "\n",
        "l5 = conv1(96,  conv2(96,  l4))\n",
        "l5 = s_e(l5)\n",
        "\n",
        "l6 = conv1(128, conv2(128, l5))\n",
        "l6 = s_e(l6)\n",
        "\n",
        "\n",
        "n0, n1, c = l6.shape[-3:]\n",
        "f0 = layers.Reshape([-1, 1, 1, n0 * n1 * c])(l6)\n",
        "# --- Define logits\n",
        "logits = layers.Conv3D(filters = 2, kernel_size = 1)(f0)\n",
        "\n",
        "# --- Create model\n",
        "backbone = Model(inputs=x, outputs=logits)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeGCm3hKHDpB",
        "outputId": "b4843117-aaa2-4997-b1c6-eab756189933"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, None, 1, 1, 2) dtype=float32 (created by layer 'conv3d_23')>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUOYozjNn8ho"
      },
      "source": [
        "### Define training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "H6eHjAT9n8ho"
      },
      "outputs": [],
      "source": [
        "# --- Define inputs\n",
        "inputs = {\n",
        "    'dat': Input(shape = (1, 128, 128, 1), name = 'dat'),\n",
        "    'lbl': Input(shape = (1, 1, 1, 1,), name = 'lbl')}\n",
        "\n",
        "# --- Define model\n",
        "logits = backbone(inputs['dat'])\n",
        "\n",
        "# --- Define loss\n",
        "sce = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss = sce(y_true=inputs['lbl'], y_pred=logits)\n",
        "# --- Define metric\n",
        "acc = metrics.sparse_categorical_accuracy(y_true=inputs['lbl'], y_pred=logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ag_-HMYNn8hp"
      },
      "source": [
        "Now, we are ready to create the `training` model and add the corresponding loss and accuracy tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "90FRkhXln8hp"
      },
      "outputs": [],
      "source": [
        "# --- Create model\n",
        "training = Model(inputs=inputs, outputs={'logits': logits, 'loss': loss, 'acc': acc})\n",
        "\n",
        "# --- Add loss\n",
        "training.add_loss(loss)\n",
        "\n",
        "# --- Add metric\n",
        "training.add_metric(acc, name = 'acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU2Apq-1n8hp"
      },
      "source": [
        "### Compiling\n",
        "\n",
        "Once the `training` model has been created, use the following to define an optimizer and compile:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0DNMhn9Un8hp"
      },
      "outputs": [],
      "source": [
        "# --- Define optimizer \n",
        "optimizer = optimizers.Adam(learning_rate = 2e-4)\n",
        "\n",
        "# --- Compile model\n",
        "training.compile(optimizer = optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfZKkDPqn8hp"
      },
      "source": [
        "The model is now compiled and ready for training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt4d2Nhqn8hp"
      },
      "source": [
        "### In-memory data\n",
        "\n",
        "To speed up training, consider loading all your model data into RAM memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmXucHC4n8hp",
        "outputId": "4270d2bf-a905-4c3c-c7fd-edee168955e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-04-22 17:09:25 ] [====================] 100.000% : Iterating | 000203    "
          ]
        }
      ],
      "source": [
        "# --- Load data into memory for faster training\n",
        "client.load_data_in_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GVUbO0on8hq"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPC7_9Zzn8hq",
        "outputId": "ad6df01d-ccb9-4765-9fe1-ce680fe9deac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1556 - acc: 0.9337\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1136 - acc: 0.9500\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1361 - acc: 0.9550\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.1377 - acc: 0.9500\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.1285 - acc: 0.9463 - val_loss: 0.2372 - val_acc: 0.9125\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1172 - acc: 0.9525\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.1254 - acc: 0.9388\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1294 - acc: 0.9513\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1313 - acc: 0.9400\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 3s 35ms/step - loss: 0.1019 - acc: 0.9625 - val_loss: 0.2345 - val_acc: 0.9150\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0962 - acc: 0.9575\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1620 - acc: 0.9425\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1181 - acc: 0.9600\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 2s 24ms/step - loss: 0.0829 - acc: 0.9650\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 3s 34ms/step - loss: 0.0725 - acc: 0.9663 - val_loss: 0.2363 - val_acc: 0.9150\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0625 - acc: 0.9725\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0637 - acc: 0.9725\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0498 - acc: 0.9775\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0567 - acc: 0.9800\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 3s 33ms/step - loss: 0.0690 - acc: 0.9762 - val_loss: 0.2342 - val_acc: 0.9137\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0694 - acc: 0.9725\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0719 - acc: 0.9688\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.1092 - acc: 0.9575\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0812 - acc: 0.9675\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 3s 35ms/step - loss: 0.0780 - acc: 0.9688 - val_loss: 0.2604 - val_acc: 0.9013\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0917 - acc: 0.9613\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 2s 22ms/step - loss: 0.0642 - acc: 0.9712\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.0600 - acc: 0.9787\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 3s 25ms/step - loss: 0.0813 - acc: 0.9700\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 0.0552 - acc: 0.9762 - val_loss: 0.2142 - val_acc: 0.9212\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88359c6110>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "training.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=100, \n",
        "    epochs=30,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=100,\n",
        "    validation_freq=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XqK40Rin8hq"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the data aggregated via a test generator.\n",
        "\n",
        "**Important**: In this assignment, you must obtain >80% performance accuracy to recieve full credit. Accuracy is determined on slice-by-slice performance accuracy as demonstrated in the tutorial; please refer to tutorial materials if you have questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pAyonnegn8hq"
      },
      "outputs": [],
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True, expand=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b0XELSSn8hq"
      },
      "source": [
        "**Note**: this cell is used only to check for model performance prior to submission. It will not be graded. Once submitted, your model will be benchmarked against the (same) validation cohort to determine final algorithm performance and grade. If your evaluation code above is correct the algorithm accuracy should match and you can be confident that you will recieve full credit for the assignment. Once you are satisfied with your model, proceed to submission of your assignment below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IJCNkFDn8hq"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **validation** cohort statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that there are at least three columns in the `*.csv` file:\n",
        "\n",
        "* true (ground-truth)\n",
        "* pred (prediction)\n",
        "* corr (correction prediction, True or False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "trues = []\n",
        "preds = []\n",
        "\n",
        "for x, _ in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    logits = backbone.predict(x['dat'])\n",
        "\n",
        "    # --- Argmax\n",
        "    pred = np.squeeze(np.argmax(logits, axis=-1))\n",
        "\n",
        "    trues.append(x['lbl'].ravel())\n",
        "    preds.append(pred.ravel())\n",
        "\n",
        "trues = np.concatenate(trues)\n",
        "preds = np.concatenate(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbo3vCNfO-If",
        "outputId": "354a15d0-8310-40da-f394-d9ff36fa9cda"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-04-22 17:11:42 ] [====================] 100.000% : Iterating | 000041    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWVGfxZfn8hq",
        "outputId": "866e1c45-bc54-4d89-9479-afc83334cb15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9324148687288797\n"
          ]
        }
      ],
      "source": [
        "# --- Create *.csv\n",
        "df = pd.DataFrame(index=np.arange(preds.size))\n",
        "\n",
        "# --- Define columns\n",
        "df['true'] = trues\n",
        "df['pred'] = preds\n",
        "df['corr'] = df['true'] == df['pred']\n",
        "\n",
        "# --- Print accuracy\n",
        "print(df['corr'].mean())\n",
        "                              \n",
        "# --- Serialize *.csv\n",
        "df.to_csv('./wjhan_results.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOAov3eZn8hq"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission (in Google Colab this should save your model file into your personal Google Drive):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTX9Lrb9n8hq",
        "outputId": "dbb11f3f-09f2-419c-a9c2-1b7ff679ee62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# --- Serialize a model\n",
        "backbone.save('./wjhan_model.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6c_D_tGn8hq"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}