{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESm_vfLWiiHT"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will train a convolutional neural network (CNN) on the CIFAR-10 dataset.\n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCWC0sD7iiHW"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook\n",
        "* final trained `*.hdf5` model file\n",
        "* final compiled `*.csv` file with performance statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQvRtCExiiHW"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1GHrYj0iiHX"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLKqY2_oiiHX"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BEtCG4ENiiHX",
        "outputId": "25a94c6e-d247-4e16-eeaf-b493ea62ee77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jarvis-md\n",
            "  Downloading jarvis_md-0.0.1a17-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▋                            | 10 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 40 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.21.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.3.5)\n",
            "Collecting pyyaml>=5.2\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 24.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->jarvis-md) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->jarvis-md) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2021.10.8)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a17 pyyaml-6.0\n"
          ]
        }
      ],
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urwzr-xOiiHY"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ch6X57VHiiHY"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd\n",
        "from tensorflow.keras import Input, Model, models, layers, losses, metrics, optimizers\n",
        "from jarvis.train import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H1LDsSBiiHZ"
      },
      "source": [
        "# Data\n",
        "\n",
        "As in the tutorial, data for this assignment will consist of the CIFAR-10 dataset comprising 10 different everyday objects (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). The following lines of code will:\n",
        "\n",
        "1. Download the dataset (if not already present) \n",
        "2. Prepare the necessary Python generators to iterate through dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VnZonxOwiiHZ",
        "outputId": "55b81769-dd33-478e-b0ae-c23bfe256506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-04-14 22:53:45 ] [====================] 100.000% : Iterating | 000001    "
          ]
        }
      ],
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='cifar')\n",
        "\n",
        "# --- Prepare generators and model inputs\n",
        "configs = {'batch': {'size': 36}}\n",
        "gen_train, gen_valid, client = datasets.prepare(name='cifar', configs=configs, custom_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXXf-1sMiiHZ"
      },
      "source": [
        "*Note*: by default a batch size of `36` is used in this block of code. Feel free to experiment with larger or smaller values in assignment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs, _  = next(gen_train)"
      ],
      "metadata": {
        "id": "rZ1VWrOLKdnK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in xs.items():\n",
        "    print('key = {} : shape = {}'.format(k.ljust(7), v.shape))"
      ],
      "metadata": {
        "id": "iL5_08flK66L",
        "outputId": "2e434af9-b723-4644-cb7b-3ffbc05baea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key = dat     : shape = (36, 32, 32, 3)\n",
            "key = class   : shape = (36, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8c-IEciiHZ"
      },
      "source": [
        "# Training\n",
        "\n",
        "In this assignment we will train a basic convolutional neural network on the CIFAR-10 dataset. At minumum you must include the following baseline techniques covered in the tutorial:\n",
        "\n",
        "* convolutional operations\n",
        "* batch normalization\n",
        "* activation function\n",
        "* subsampling\n",
        "\n",
        "You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK8paqhZiiHa"
      },
      "source": [
        "### Define backbone model\n",
        "\n",
        "Feel free to use the `lambda` helper functions as demonstrated in the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "RR7nktlliiHa"
      },
      "outputs": [],
      "source": [
        "## --- Define input\n",
        "x = Input(shape=(32,32,3), dtype='float32')\n",
        "\n",
        "# --- Define model\n",
        "kwargs = {\n",
        "    'kernel_size': (3,3),\n",
        "  'padding' : 'same'\n",
        "}\n",
        "conv = lambda x, filters, strides : layers.Conv2D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2))))\n",
        "\n",
        "l1 = conv1(16, x)\n",
        "l2 = conv1(24, conv2(24, l1))\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "\n",
        "f0 = layers.Flatten()(l5)\n",
        "h0 = 256\n",
        "h1 = layers.Dense(h0, activation='relu')(f0)\n",
        "h2 = layers.Dense(128, activation = 'relu')(h1)\n",
        "h3 = layers.Dense(64, activation = 'relu')(h2)\n",
        "h4 = layers.Dense(32, activation = 'relu')(h3)\n",
        "# --- Define logits\n",
        "logits = layers.Dense(10, name = 'class')(h4)\n",
        "\n",
        "# --- Create model\n",
        "backbone = Model(inputs=x, outputs=logits)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "id": "vEdjd7s6L43b",
        "outputId": "74a1c7ee-deea-4af8-9535-d7aeb97020d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'class')>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = backbone.predict(xs['dat'])"
      ],
      "metadata": {
        "id": "GFFrRUm9NJjZ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCf69CV0iiHa"
      },
      "source": [
        "### Define training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "TpPpnZwwiiHa",
        "outputId": "90599692-9885-4b28-b378-c3163eddd617",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2.302547, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# --- Define inputs\n",
        "inputs = {\n",
        "    'dat': Input(shape = (32, 32, 3), name = 'dat'),\n",
        "    'class': Input(shape = (1,), name = 'class')}\n",
        "\n",
        "# --- Define model\n",
        "logits = backbone(inputs['dat'])\n",
        "\n",
        "# --- Define loss\n",
        "sce = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "print(sce(y_true=xs['class'], y_pred=scores))\n",
        "loss = sce(y_true = inputs['class'], y_pred = logits)\n",
        "# --- Define metric\n",
        "acc = metrics.sparse_categorical_accuracy(y_true=inputs['class'], y_pred=logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDIVi728iiHa"
      },
      "source": [
        "Now, we are ready to create the `training` model and add the corresponding loss and accuracy tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "SOoDGFbxiiHa"
      },
      "outputs": [],
      "source": [
        "# --- Create model\n",
        "training = Model(inputs=inputs, outputs={'logits': logits, 'loss': loss, 'acc': acc})\n",
        "\n",
        "# --- Add loss\n",
        "training.add_loss(loss)\n",
        "\n",
        "# --- Add metric\n",
        "training.add_metric(acc, name = 'acc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfZk-gWMiiHa"
      },
      "source": [
        "### Compiling\n",
        "\n",
        "Once the `training` model has been created, use the following to define an optimizer and compile:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "B1qANzfDiiHa"
      },
      "outputs": [],
      "source": [
        "# --- Define optimizer \n",
        "optimizer = optimizers.Adam(learning_rate=2e-4)\n",
        "\n",
        "# --- Compile model\n",
        "training.compile(optimizer = optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgBwgLy_iiHb"
      },
      "source": [
        "The model is now compiled and ready for training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLf-hsgyiiHb"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "j16sNZIaiiHb",
        "outputId": "433d6ee1-7acc-4a95-b842-91cd40cc06cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 29s 108ms/step - loss: 2.1162 - acc: 0.1989\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 1.8039 - acc: 0.3346\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 27s 110ms/step - loss: 1.6468 - acc: 0.3959\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 41s 162ms/step - loss: 1.5716 - acc: 0.4253 - val_loss: 1.5128 - val_acc: 0.4447\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 27s 110ms/step - loss: 1.4873 - acc: 0.4580\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 1.4434 - acc: 0.4794\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 1.4055 - acc: 0.4960\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 40s 160ms/step - loss: 1.3639 - acc: 0.5097 - val_loss: 1.4730 - val_acc: 0.4748\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 27s 110ms/step - loss: 1.3363 - acc: 0.5168\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 1.2815 - acc: 0.5339\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 1.2518 - acc: 0.5506\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 1.2236 - acc: 0.5548 - val_loss: 1.2678 - val_acc: 0.5358\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 29s 115ms/step - loss: 1.2135 - acc: 0.5626\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 27s 110ms/step - loss: 1.1916 - acc: 0.5731\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 1.1311 - acc: 0.5973\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 39s 157ms/step - loss: 1.1085 - acc: 0.6069 - val_loss: 1.2876 - val_acc: 0.5430\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 1.1049 - acc: 0.6096\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 27s 107ms/step - loss: 1.0821 - acc: 0.6152\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 28s 110ms/step - loss: 1.0752 - acc: 0.6183\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 40s 162ms/step - loss: 1.0552 - acc: 0.6263 - val_loss: 1.1473 - val_acc: 0.5948\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 28s 113ms/step - loss: 0.9800 - acc: 0.6532\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 28s 112ms/step - loss: 0.9742 - acc: 0.6570\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 0.9750 - acc: 0.6537\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 47s 189ms/step - loss: 0.9716 - acc: 0.6526 - val_loss: 1.1255 - val_acc: 0.6046\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 27s 110ms/step - loss: 0.9729 - acc: 0.6578\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 0.9188 - acc: 0.6726\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 27s 107ms/step - loss: 0.8824 - acc: 0.6932\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 37s 150ms/step - loss: 0.8977 - acc: 0.6814 - val_loss: 1.1310 - val_acc: 0.6041\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 26s 106ms/step - loss: 0.8871 - acc: 0.6950\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 27s 110ms/step - loss: 0.8926 - acc: 0.6914\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 27s 107ms/step - loss: 0.8455 - acc: 0.7027\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 38s 151ms/step - loss: 0.8077 - acc: 0.7180 - val_loss: 1.0933 - val_acc: 0.6211\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 26s 104ms/step - loss: 0.8191 - acc: 0.7118\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 26s 103ms/step - loss: 0.8249 - acc: 0.7146\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 26s 103ms/step - loss: 0.8077 - acc: 0.7149\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 38s 151ms/step - loss: 0.8112 - acc: 0.7151 - val_loss: 1.1070 - val_acc: 0.6254\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 26s 103ms/step - loss: 0.7009 - acc: 0.7582\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 26s 106ms/step - loss: 0.7526 - acc: 0.7374\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 0.7447 - acc: 0.7399\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 36s 146ms/step - loss: 0.7494 - acc: 0.7360 - val_loss: 1.0975 - val_acc: 0.6263\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 26s 104ms/step - loss: 0.7613 - acc: 0.7319\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 25s 101ms/step - loss: 0.6930 - acc: 0.7608\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 26s 103ms/step - loss: 0.6688 - acc: 0.7619\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 42s 168ms/step - loss: 0.6833 - acc: 0.7560 - val_loss: 1.1428 - val_acc: 0.6224\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 27s 108ms/step - loss: 0.6871 - acc: 0.7560\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 25s 101ms/step - loss: 0.7031 - acc: 0.7550\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 27s 106ms/step - loss: 0.6701 - acc: 0.7678\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 41s 163ms/step - loss: 0.5907 - acc: 0.7970 - val_loss: 1.1707 - val_acc: 0.6270\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 28s 111ms/step - loss: 0.6254 - acc: 0.7831\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 27s 109ms/step - loss: 0.6372 - acc: 0.7729\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9eea35f2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "training.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=250, \n",
        "    epochs=50,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=250,\n",
        "    validation_freq=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmzxkvOHiiHb"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `backbone.predict(...)` or `training.predict(...)` on the data aggregated via a test generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "RyfrSFXliiHb",
        "outputId": "e7adb205-c66e-4353-b624-0948a2853341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2022-04-15 02:03:52 ] [====================] 100.000% : Iterating | 012000    "
          ]
        }
      ],
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True)\n",
        "\n",
        "# --- Aggregate all examples\n",
        "xs = {'dat' : [], 'class': []}\n",
        "\n",
        "for x, _ in test_valid:\n",
        "  xs['dat'].append(x['dat'])\n",
        "  xs['class'].append(x['class'])\n",
        "\n",
        "xs = {\n",
        "    'dat': np.concatenate(xs['dat']),\n",
        "    'class' : np.concatenate(xs['class'])\n",
        "}\n",
        "# --- Predict\n",
        "outputs = training.predict(xs)\n",
        "# --- Argmax\n",
        "pred = np.argmax(outputs['logits'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "id": "YtiCjpbHtYqm",
        "outputId": "728fbd21-4d84-412a-fc14-b3a8b38d22c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 1 7 ... 3 5 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(index=np.arange(pred.size))\n",
        "\n",
        "# --- Define columns\n",
        "df['true'] = xs['class']\n",
        "df['pred'] = pred\n",
        "df['corr'] = df['true'] == df['pred']\n",
        "\n",
        "# --- Print accuracy\n",
        "print(df['corr'].mean())"
      ],
      "metadata": {
        "id": "45OMgkWKVQCx",
        "outputId": "2cff4e59-a968-44f6-b26b-56a4687037f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6298333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4GulvQ9iiHb"
      },
      "source": [
        "**Note**: this cell is used only to check for model performance. It will not be graded. Once you are satisfied with your model, proceed to submission of your assignment below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywdrA7iOiiHb"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **validation** cohort statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that there are at least three columns in the `*.csv` file:\n",
        "\n",
        "* true (ground-truth)\n",
        "* pred (prediction)\n",
        "* corr (correction prediction, True or False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "5Gn_jniliiHb"
      },
      "outputs": [],
      "source": [
        "# --- Create *.csv\n",
        "\n",
        "                              \n",
        "# --- Serialize *.csv\n",
        "df.to_csv('./wjhan_results.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv_ihKBNiiHb"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "QHvFzf25iiHb",
        "outputId": "c13a27df-bcc1-45b3-80e8-4bef254ea0f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# --- Serialize a model\n",
        "backbone.save('./wjhan_model.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DcF1CYaiiHb"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}