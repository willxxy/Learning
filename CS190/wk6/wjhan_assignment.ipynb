{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhi7TLuZfBqJ"
      },
      "source": [
        "# Midterm\n",
        "\n",
        "The midterm project will consist of a comparison between several CNN architectures for organ segmentation. The goal is both to create a high-performing algorithm for the target task, as well as to analyze performance across several different architecture permutations. In total, three different network designs will be tested. As each model is built and trained, ensure to serialize the final model `*.hdf5` file before moving to the next iteration.\n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5m_66c-fBqL"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook\n",
        "* final trained `*.hdf5` model files for all three models\n",
        "* final compiled `*.csv` file with performance statistics across the different architectures\n",
        "* final 1-page write-up with methods and results of experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qem0iIY9fBqM"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9hLqJOTfBqM"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uNiQYg0fBqM"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUPBObMefBqN",
        "outputId": "f653fc46-2d31-4745-f1cb-61c96a00219b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jarvis-md\n",
            "  Downloading jarvis_md-0.0.1a17-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▋                            | 10 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 40 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 81 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 89 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.3.5)\n",
            "Collecting pyyaml>=5.2\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 38.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 44.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 40 kB 48.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 51 kB 45.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 61 kB 47.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 71 kB 48.7 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 81 kB 50.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 92 kB 51.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 102 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 112 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 122 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 133 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 143 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 153 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 163 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 174 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 184 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 194 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 204 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 215 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 225 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 235 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 245 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 256 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 266 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 276 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 286 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 296 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 307 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 317 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 327 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 337 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 348 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 358 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 368 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 378 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 389 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 399 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 409 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 419 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 430 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 440 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 450 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 460 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 471 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 481 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 491 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 501 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 512 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 522 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 532 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 542 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 552 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 563 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 573 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 583 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 593 kB 53.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 596 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.5.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->jarvis-md) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->jarvis-md) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2022.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a17 pyyaml-6.0\n"
          ]
        }
      ],
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vSML-PTfBqN"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZHKOuXaYfBqO"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model, models, layers, losses, metrics, optimizers\n",
        "from jarvis.train import datasets\n",
        "from jarvis.utils.display import imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JB-GCY1fBqO"
      },
      "source": [
        "# Data\n",
        "\n",
        "The data used in this tutorial will consist of kidney tumor CT exams derived from the Kidney Tumor Segmentation Challenge (KiTS). More information about the KiTS Challenge can be found here: https://kits21.kits-challenge.org/. In this exercise, we will use this dataset to derive a model for kidney segmentation. The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/ct_kits`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdogQomQfBqO",
        "outputId": "176b5d8e-6e0f-46b6-c7d2-463f88142571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2022-05-04 01:03:33 ] [====================] 100.000% : Extracting archive (0000818 / 0000818) "
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'code': '/data/raw/ct_kits', 'data': '/data/raw/ct_kits'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='ct/kits')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQmnocAufBqP"
      },
      "source": [
        "Since the algorithms below may require slightly different model inputs, the required generators and inputs will be defined dyanically in the code blocks later in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vxajIoFfBqP"
      },
      "source": [
        "# Training\n",
        "\n",
        "A total of three different network architectures will be tested. The goal is to compare the incremental benefit of several design choices. After building and training each model to convergence, do not forget to save each model as a separate `*.hdf5` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWPevK_0fBqP"
      },
      "source": [
        "## 1. 2D U-Net\n",
        "\n",
        "In this algorithm a standard 2D U-Net architecture will be used to perform organ segmentation. The algorithm input will include an `96 x 96` resolution 2D slice from an abdominal CT exam. Key customizations to the standard U-Net architecture that should be implemented (as in the week 5 and week 6 tutorials) include:\n",
        "\n",
        "* same padding (vs. valid padding)\n",
        "* strided convolutions (vs. max-pooling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lJWIkGaGIxf"
      },
      "source": [
        "### 2D Lambda and Functions\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Gko2UzE6GMGW"
      },
      "outputs": [],
      "source": [
        "# ---- kwargs dic, lambda, se func, dsc func\n",
        "\n",
        "kwargs = {\n",
        "    'kernel_size': (1, 3, 3),\n",
        "    'padding': 'same'\n",
        "}\n",
        "\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters = filters, strides = strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides = 1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides = (1, 2, 2))))\n",
        "\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters = filters, strides = strides, **kwargs)(x)\n",
        "tran2 = lambda filters, x: relu(norm(tran(x, filters, strides = (1,2 ,2))))\n",
        "\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "\n",
        "def se(layer):\n",
        "  \n",
        "  sqz = layers.AveragePooling3D((1, layer.shape[2], layer.shape[3]))(layer)\n",
        "  cha = int(layer.shape[-1]/4)\n",
        "  exc = layers.Conv3D(filters = cha, kernel_size = 1, activation = 'relu')(sqz)\n",
        "  sca = layers.Conv3D(filters = layer.shape[-1], kernel_size = 1, activation = 'sigmoid')(exc)\n",
        "\n",
        "  return layer * sca\n",
        "\n",
        "def calc_dsc(y_true, y_pred, c=1):\n",
        "\n",
        "  true = y_true[..., 0] == c\n",
        "  pred = tf.math.argmax(y_pred, axis =-1) == c\n",
        "\n",
        "  A = tf.math.count_nonzero(true & pred) * 2\n",
        "  B = tf.math.count_nonzero(true) + tf.math.count_nonzero(pred)\n",
        "\n",
        "  return tf.math.divide_no_nan(\n",
        "      tf.cast(A, tf.float32),\n",
        "      tf.cast(B, tf.float32)\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxug_zCfBqP"
      },
      "source": [
        "### Create generators and inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iVUt91dvfBqP"
      },
      "outputs": [],
      "source": [
        "# --- Input ==> 1 x 96 x 96 x 1\n",
        "configs = {'batch': {'size': 16}}\n",
        "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='2d-bin', configs=configs, custom_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htJ7ahEPfBqQ"
      },
      "source": [
        "### Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QIMzFp-SfBqQ"
      },
      "outputs": [],
      "source": [
        "# --- Create backbone model\n",
        "\n",
        "x = Input(shape=(None, 96, 96, 1), dtype='float32')\n",
        "\n",
        "\n",
        "l1 = conv1(8, x)\n",
        "\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "\n",
        "l3 = conv1(32, conv2(32,l2))\n",
        "\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "\n",
        "l6 = tran2(48, l5)\n",
        "\n",
        "l7 = tran2(32, conv1(48, concat(l4, l6))) \n",
        "\n",
        "l8 = tran2(16, conv1(32, concat(l3, l7)))\n",
        "\n",
        "l9 = tran2(8, conv1(16, concat(l2, l8)))\n",
        "\n",
        "l10 = conv1(8, l9)\n",
        "\n",
        "logits = layers.Conv3D(filters = 2, **kwargs)(l10)\n",
        "\n",
        "backbone = Model(inputs=x, outputs=logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4yW8_bJsfBqQ"
      },
      "outputs": [],
      "source": [
        "# --- Create training model\n",
        "\n",
        "inputs = {\n",
        "    'dat': Input(shape=(None, 96, 96, 1), name='dat'),\n",
        "    'lbl': Input(shape=(None, 96, 96, 1), name='lbl')}\n",
        "\n",
        "logits = backbone(inputs['dat'])\n",
        "\n",
        "sce = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss = sce(y_true=inputs['lbl'], y_pred=logits)\n",
        "\n",
        "dsc = calc_dsc(y_true=inputs['lbl'], y_pred=logits)\n",
        "\n",
        "training = Model(inputs=inputs, outputs={'logits': logits, 'loss': loss, 'dsc': dsc})\n",
        "\n",
        "training.add_loss(loss)\n",
        "training.add_metric(dsc, name = 'dsc')\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=2e-4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4r5kIlrfBqR"
      },
      "source": [
        "### Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giRjTnV8fBqR",
        "outputId": "fd59efa9-bac0-4482-c7eb-dc28532ba41c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2022-05-04 01:04:00 ] [====================] 100.000% : Iterating | 000402    Epoch 1/10\n",
            "100/100 [==============================] - 19s 43ms/step - loss: 0.3948 - dsc: 0.1170\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.1849 - dsc: 0.4017\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 4s 37ms/step - loss: 0.1239 - dsc: 0.6765\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 4s 39ms/step - loss: 0.0782 - dsc: 0.9012\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 7s 66ms/step - loss: 0.0550 - dsc: 0.9193 - val_loss: 0.0655 - val_dsc: 0.8874\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 3s 26ms/step - loss: 0.0436 - dsc: 0.9346\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.0391 - dsc: 0.9390\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 4s 36ms/step - loss: 0.0349 - dsc: 0.9426\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 4s 38ms/step - loss: 0.0319 - dsc: 0.9451\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 6s 63ms/step - loss: 0.0290 - dsc: 0.9492 - val_loss: 0.0345 - val_dsc: 0.9372\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa672897cd0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Compile model\n",
        "training.compile(optimizer=optimizer)\n",
        "\n",
        "client.load_data_in_memory()\n",
        "\n",
        "# --- Train the model\n",
        "training.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=100, \n",
        "    epochs=10,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=100,\n",
        "    validation_freq=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAl2UnL_IobF",
        "outputId": "c95bc9cc-e80b-48c6-c671-6269d61c1d5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2022-05-04 01:05:53 ] [====================] 100.000% : Iterating | 000321    "
          ]
        }
      ],
      "source": [
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "dsc_2d_valid = []\n",
        "dsc_2d_train = []\n",
        "\n",
        "for x, _ in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    outputs = training.predict(x)\n",
        "\n",
        "    # --- Argmax\n",
        "    dsc_2d_valid.append(outputs['dsc'])\n",
        "\n",
        "dsc_2d_valid = np.array(dsc_2d_valid)\n",
        "\n",
        "for x, _ in test_train:\n",
        "    \n",
        "    # --- Predict\n",
        "    outputs = training.predict(x)\n",
        "\n",
        "    # --- Argmax\n",
        "    dsc_2d_train.append(outputs['dsc'])\n",
        "\n",
        "dsc_2d_train = np.array(dsc_2d_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqu2KLsYIwya",
        "outputId": "12fecde3-3236-4436-af27-d3c21e72d03a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9536712188215642\n",
            "0.930788650188917\n"
          ]
        }
      ],
      "source": [
        "twod_df_train = pd.DataFrame(index=np.arange(dsc_2d_train.size))\n",
        "twod_df_train['Dice score'] = dsc_2d_train\n",
        "\n",
        "print(twod_df_train['Dice score'].mean())\n",
        "\n",
        "twod_df_valid = pd.DataFrame(index=np.arange(dsc_2d_valid.size))\n",
        "twod_df_valid['Dice score'] = dsc_2d_valid\n",
        "\n",
        "print(twod_df_valid['Dice score'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TWhCeGucJbOL"
      },
      "outputs": [],
      "source": [
        "twod_df_train.to_csv('./dice_results_2D_train.csv')\n",
        "twod_df_valid.to_csv('./dice_results_2D_valid.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoUkm0_EJAf7",
        "outputId": "89ca103c-eb2e-49ce-8a7e-af156aaa824b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "backbone.save('./wjhan_2Dmodel.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJg347cMfBqR"
      },
      "source": [
        "## 2. 3D U-Net\n",
        "\n",
        "In this algorithm, the original 2D model is modified to a full 3D model. The algorithm input will include an `96 x 96 x 96` resolution 3D volume from an abdominal CT exam. To ensure a fair comparison, recommend using similar network design and training hyperparameters as in the first 2D only model above. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i21C_BTBfBqR"
      },
      "source": [
        "### Create generators and inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B0Ct3gVTfBqR"
      },
      "outputs": [],
      "source": [
        "# --- Input ==> 96 x 96 x 96 x 1\n",
        "configs = {'batch': {'size': 16}}\n",
        "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='3d-bin', configs=configs, custom_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w28d_EerTOKx"
      },
      "source": [
        "### 3D Lambda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kAqEHOuqTOhG"
      },
      "outputs": [],
      "source": [
        "# ---- kwargs dic, lambda, se func, dsc func\n",
        "\n",
        "kwargs = {\n",
        "    'kernel_size': (3, 3, 3),\n",
        "    'padding': 'same',\n",
        "    'kernel_initializer': 'he_normal'\n",
        "}\n",
        "\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters = filters, strides = strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides = 1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides = (2, 2, 2))))\n",
        "\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters = filters, strides = strides, **kwargs)(x)\n",
        "tran2 = lambda filters, x: relu(norm(tran(x, filters, strides = (2,2 ,2))))\n",
        "\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9E-p8jnfBqR"
      },
      "source": [
        "### Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "C1bSqQrvfBqR"
      },
      "outputs": [],
      "source": [
        "# --- Create backbone model\n",
        "\n",
        "x = Input(shape=(96, 96, 96, 1), dtype='float32')\n",
        "\n",
        "l1 = conv1(8, x)\n",
        "\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "\n",
        "l3 = conv1(32, conv2(32, l2))\n",
        "\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "\n",
        "\n",
        "l6  = tran2(48, l5)\n",
        "\n",
        "l7  = tran2(32, conv1(48, concat(l4, l6)))\n",
        "\n",
        "l8  = tran2(16, conv1(32, concat(l3, l7)))\n",
        "\n",
        "l9  = conv1(8, tran2(8,  conv1(16, concat(l2, l8))))\n",
        "\n",
        "logits = layers.Conv3D(filters=2, **kwargs)(l9)\n",
        "\n",
        "\n",
        "logits = {\n",
        "    \n",
        "    'c0': layers.Conv3D(filters=2, **kwargs)(l9),\n",
        "    'c1': layers.Conv3D(filters=2, **kwargs)(l8),\n",
        "}\n",
        "backbone = Model(inputs = x, outputs = logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CRwi_5effBqR"
      },
      "outputs": [],
      "source": [
        "# --- Create training model\n",
        "inputs = {\n",
        "    'dat': Input(shape=(96, 96, 96, 1), name='dat'),\n",
        "    'lbl': Input(shape=(96, 96, 96, 1), name='lbl')}\n",
        "logits = backbone(inputs['dat'])\n",
        "\n",
        "\n",
        "loss = {}\n",
        "true = inputs['lbl']\n",
        "\n",
        "for c in sorted(logits.keys()):\n",
        "    \n",
        "    if c != 'c0':\n",
        "        true = layers.MaxPooling3D(pool_size=(2, 2, 2))(true)\n",
        "    \n",
        "    loss[c] = losses.SparseCategoricalCrossentropy(from_logits=True, name='sce-' + c)(\n",
        "        y_true=true,\n",
        "        y_pred=logits[c])\n",
        "\n",
        "\n",
        "dsc = calc_dsc(y_true=inputs['lbl'], y_pred=logits['c0'])\n",
        "\n",
        "training = Model(inputs=inputs, outputs={**logits, **loss, **{'dsc': dsc}})\n",
        "\n",
        "for l in loss.values():\n",
        "    training.add_loss(l)\n",
        "\n",
        "training.add_metric(dsc, name='dsc')\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=2e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_eMD4yzfBqR"
      },
      "source": [
        "### Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k-pKizffBqR",
        "outputId": "0a222f05-3ce2-4484-a007-aa99e3c7df6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2022-05-04 01:08:29 ] [====================] 100.000% : Iterating | 000402    Epoch 1/10\n",
            "100/100 [==============================] - 115s 1s/step - loss: 0.5717 - dsc: 0.5263\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.1110 - dsc: 0.9350\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0621 - dsc: 0.9564\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.0445 - dsc: 0.9644\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 132s 1s/step - loss: 0.0353 - dsc: 0.9689 - val_loss: 0.0736 - val_dsc: 0.9175\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 107s 1s/step - loss: 0.0292 - dsc: 0.9729\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0257 - dsc: 0.9743\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 109s 1s/step - loss: 0.0233 - dsc: 0.9756\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 108s 1s/step - loss: 0.0210 - dsc: 0.9772\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 132s 1s/step - loss: 0.0188 - dsc: 0.9793 - val_loss: 0.0631 - val_dsc: 0.9350\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa6728f8a50>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Compile model\n",
        "training.compile(optimizer = optimizer)\n",
        "\n",
        "client.load_data_in_memory()\n",
        "# --- Train the model\n",
        "training.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=100, \n",
        "    epochs=10,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=100,\n",
        "    validation_freq=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2r3AGB5cBjH",
        "outputId": "cd12d572-386b-47be-df3a-73d366c14725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2022-05-04 01:28:27 ] [====================] 100.000% : Iterating | 000321    "
          ]
        }
      ],
      "source": [
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "dsc_3d_valid = []\n",
        "dsc_3d_train = []\n",
        "\n",
        "for x, _ in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    outputs = training.predict(x)\n",
        "\n",
        "    # --- Argmax\n",
        "    dsc_3d_valid.append(outputs['dsc'])\n",
        "\n",
        "dsc_3d_valid = np.array(dsc_3d_valid)\n",
        "\n",
        "\n",
        "for x, _ in test_train:\n",
        "    \n",
        "    # --- Predict\n",
        "    outputs = training.predict(x)\n",
        "\n",
        "    # --- Argmax\n",
        "    dsc_3d_train.append(outputs['dsc'])\n",
        "\n",
        "dsc_3d_train = np.array(dsc_3d_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl4oLxC9cJGJ",
        "outputId": "1a9fe6b1-1255-4a03-d24e-65c8d2cb12de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9639075910933664\n",
            "0.9334891850565686\n"
          ]
        }
      ],
      "source": [
        "threed_df_train = pd.DataFrame(index=np.arange(dsc_3d_train.size))\n",
        "threed_df_train['Dice score'] = dsc_3d_train\n",
        "\n",
        "print(threed_df_train['Dice score'].mean())\n",
        "\n",
        "threed_df_valid = pd.DataFrame(index=np.arange(dsc_3d_valid.size))\n",
        "threed_df_valid['Dice score'] = dsc_3d_valid\n",
        "\n",
        "print(threed_df_valid['Dice score'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WUP4EkuoJYz",
        "outputId": "db34163c-ad3a-4f62-d4dd-256bcb196f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "threed_df_train.to_csv('./dice_results_3D_train.csv')\n",
        "threed_df_valid.to_csv('./dice_results_3D_valid.csv')\n",
        "backbone.save('./wjhan_3Dmodel.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuhBYh7-fBqS"
      },
      "source": [
        "## 3. Custom architecture\n",
        "\n",
        "Finally, using any of the customizations described in class, find a top-performing model that may potentially yield some incremental benefit over the two baseline models above. Modifications that may be used include (but are not limited to):\n",
        "\n",
        "* deep supervision\n",
        "* residual connections\n",
        "* added convolutions between contracting and expanding layers \n",
        "* modifications to the convolutional blocks including ResNet, Inception, SE-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "movU2V1lfBqS"
      },
      "source": [
        "### Create generators and inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wqU-G7TCfBqS"
      },
      "outputs": [],
      "source": [
        "# --- Choose input (may copy the generator code from above)\n",
        "gen_train, gen_valid, client = datasets.prepare(name='ct/kits', keyword='2d-bin', custom_layers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXG1Yx-aiPQv"
      },
      "source": [
        "### Custom Architecture Lambda and Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mHvfOv6hiTFj"
      },
      "outputs": [],
      "source": [
        "# ---- kwargs dic, lambda, se func, dsc func\n",
        "\n",
        "kwargs = {\n",
        "    'kernel_size': (1, 3, 3),\n",
        "    'padding': 'same'\n",
        "}\n",
        "\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters = filters, strides = strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides = 1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides = (1, 2, 2))))\n",
        "\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters = filters, strides = strides, **kwargs)(x)\n",
        "tran2 = lambda filters, x: relu(norm(tran(x, filters, strides = (1,2 ,2))))\n",
        "\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "\n",
        "def se(layer):\n",
        "  \n",
        "  sqz = layers.AveragePooling3D((1, layer.shape[2], layer.shape[3]))(layer)\n",
        "  cha = int(layer.shape[-1]/4)\n",
        "  exc = layers.Conv3D(filters = cha, kernel_size = 1, activation = 'relu')(sqz)\n",
        "  sca = layers.Conv3D(filters = layer.shape[-1], kernel_size = 1, activation = 'sigmoid')(exc)\n",
        "\n",
        "  return layer * sca\n",
        "\n",
        "def calc_dsc(y_true, y_pred, c=1):\n",
        "\n",
        "  true = y_true[..., 0] == c\n",
        "  pred = tf.math.argmax(y_pred, axis =-1) == c\n",
        "\n",
        "  A = tf.math.count_nonzero(true & pred) * 2\n",
        "  B = tf.math.count_nonzero(true) + tf.math.count_nonzero(pred)\n",
        "\n",
        "  return tf.math.divide_no_nan(\n",
        "      tf.cast(A, tf.float32),\n",
        "      tf.cast(B, tf.float32)\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwNJsEsCfBqS"
      },
      "source": [
        "### Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ArtOjjfKfBqS"
      },
      "outputs": [],
      "source": [
        "# --- Create backbone model\n",
        "x = Input(shape=(None, 96, 96, 1), dtype='float32')\n",
        "\n",
        "\n",
        "l1 = conv1(8, x)\n",
        "l1 = se(l1)\n",
        "\n",
        "l2 = conv1(16, conv2(16, l1))\n",
        "l2 = se(l2)\n",
        "\n",
        "l3 = conv1(32, conv2(32,l2))\n",
        "l3 = se(l3)\n",
        "\n",
        "l4 = conv1(48, conv2(48, l3))\n",
        "l4 = se(l4)\n",
        "\n",
        "l5 = conv1(64, conv2(64, l4))\n",
        "l5 = se(l5)\n",
        "\n",
        "l6 = tran2(48, l5)\n",
        "\n",
        "l7 = tran2(32, conv1(48, concat(l4, l6))) \n",
        "\n",
        "l8 = tran2(16, conv1(32, concat(l3, l7)))\n",
        "\n",
        "l9 = tran2(8, conv1(16, concat(l2, l8)))\n",
        "\n",
        "l10 = conv1(8, l9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "logits = layers.Conv3D(filters = 2, **kwargs)(l10)\n",
        "\n",
        "# --- Create model\n",
        "backbone = Model(inputs=x, outputs=logits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LMbax9UyfBqS"
      },
      "outputs": [],
      "source": [
        "# --- Create training model\n",
        "inputs = {\n",
        "    'dat': Input(shape= (None, 96, 96, 1), name = 'dat'),\n",
        "    'lbl': Input(shape = (None, 96, 96, 1), name = 'lbl')}\n",
        "\n",
        "logits = backbone(inputs['dat'])\n",
        "\n",
        "sce = losses.SparseCategoricalCrossentropy(from_logits = True)\n",
        "loss = sce(y_true=inputs['lbl'], y_pred = logits)\n",
        "\n",
        "dsc = calc_dsc(y_true = inputs['lbl'], y_pred = logits)\n",
        "\n",
        "training = Model(inputs=inputs, outputs={'logits': logits, 'loss' : loss, 'dsc' : dsc})\n",
        "\n",
        "training.add_loss(loss)\n",
        "\n",
        "training.add_metric(dsc, name = 'dsc')\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate = 2e-4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvCpuZaCfBqS"
      },
      "source": [
        "### Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C94k8mmtfBqS",
        "outputId": "91971f4d-64af-4bdf-d579-eb3b846c0559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2022-05-04 01:28:37 ] [====================] 100.000% : Iterating | 000402    Epoch 1/10\n",
            "100/100 [==============================] - 6s 28ms/step - loss: 0.5710 - dsc: 0.1988\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.2360 - dsc: 0.7378\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.1201 - dsc: 0.8656\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.0813 - dsc: 0.8933\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 5s 53ms/step - loss: 0.0615 - dsc: 0.9145 - val_loss: 0.0889 - val_dsc: 0.8161\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.0504 - dsc: 0.9248\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 3s 29ms/step - loss: 0.0424 - dsc: 0.9338\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.0395 - dsc: 0.9359\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 3s 28ms/step - loss: 0.0356 - dsc: 0.9414\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 5s 49ms/step - loss: 0.0332 - dsc: 0.9440 - val_loss: 0.0447 - val_dsc: 0.9185\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa5db29de10>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Compile model\n",
        "training.compile(optimizer = optimizer)\n",
        "client.load_data_in_memory()\n",
        "# --- Train the model\n",
        "training.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=100, \n",
        "    epochs=10,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=100,\n",
        "    validation_freq=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-JF5hZ4jV9r",
        "outputId": "6e70e821-bb6b-4e04-a95a-62d3ed5f8169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2022-05-04 01:29:53 ] [====================] 100.000% : Iterating | 000321    "
          ]
        }
      ],
      "source": [
        "test_train, test_valid = client.create_generators(test=True, expand=True)\n",
        "\n",
        "dsc_custom_valid = []\n",
        "dsc_custom_train = []\n",
        "\n",
        "for x, _ in test_valid:\n",
        "    \n",
        "    # --- Predict\n",
        "    outputs = training.predict(x)\n",
        "\n",
        "    # --- Argmax\n",
        "    dsc_custom_valid.append(outputs['dsc'])\n",
        "\n",
        "dsc_custom_valid = np.array(dsc_custom_valid)\n",
        "\n",
        "\n",
        "for x, _ in test_train:\n",
        "    \n",
        "    # --- Predict\n",
        "    outputs = training.predict(x)\n",
        "\n",
        "    # --- Argmax\n",
        "    dsc_custom_train.append(outputs['dsc'])\n",
        "\n",
        "dsc_custom_train = np.array(dsc_custom_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvFBKKVCjY5a",
        "outputId": "9214727a-225a-417f-c5d3-d33ff0381997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9498334205781931\n",
            "0.9234169717924094\n"
          ]
        }
      ],
      "source": [
        "custom_df_train = pd.DataFrame(index=np.arange(dsc_custom_train.size))\n",
        "custom_df_train['Dice score'] = dsc_custom_train\n",
        "\n",
        "print(custom_df_train['Dice score'].mean())\n",
        "\n",
        "custom_df_valid = pd.DataFrame(index=np.arange(dsc_custom_valid.size))\n",
        "custom_df_valid['Dice score'] = dsc_custom_valid\n",
        "\n",
        "print(custom_df_valid['Dice score'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q44wrLeOjhct",
        "outputId": "af434ea5-ab81-41ec-f715-e88065ec9e1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "custom_df_train.to_csv('./dice_results_custom_train.csv')\n",
        "custom_df_valid.to_csv('./dice_results_custom_valid.csv')\n",
        "backbone.save('./wjhan_custommodel.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH1310yqfBqS"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "For each of the three models, the following metrics should be calculated for **both the training and validation** cohorts:\n",
        "\n",
        "* Dice score, mean\n",
        "* Dice score, median\n",
        "* Dice score, 25th percentile\n",
        "* Dice score, 75th percentile\n",
        "\n",
        "As in prior assignments, accuracy is determined on a patient by patient (volume by volume) basis, so please calculate the Dice score values on the entire 3D volume (not slice-by-slice).\n",
        "\n",
        "### Performance\n",
        "\n",
        "The following minimum **validation cohort** performance metrics must be met for full credit:\n",
        "\n",
        "1. **2D U-Net**: mean Dice score > 0.80\n",
        "2. **3D U-Net**: mean Dice score > 0.82\n",
        "3. **Custom architecture**: mean Dice score > 0.84\n",
        "\n",
        "**Bonus**: any final model with a mean **validation cohort** Disce score > 0.96 will recieve a +5 point (+15%) extra credit towards the midterm assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCQrT40SfBqS"
      },
      "source": [
        "### Results\n",
        "\n",
        "When ready, create a `*.csv` file with your compiled **training and validation** cohort statistics for the three different models. Consider the following table format (although any format that contains the required information is sufficient):\n",
        "\n",
        "```\n",
        "          TRAINING                                VALIDATION\n",
        "          mean | median | 25th-tile | 75th-tile | mean | median | 25th-tile | 75th-tile\n",
        "model 1\n",
        "model 2\n",
        "model 3\n",
        "```\n",
        "\n",
        "As above, statistics for both training and validation should be provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH58OUeJstV7",
        "outputId": "c81d4e01-4f13-4358-96a2-c7339428c058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dice_results_2D_train.csv      dice_results_custom_valid.csv\n",
            "dice_results_2D_valid.csv      sample_data\n",
            "dice_results_3D_train.csv      wjhan_2Dmodel.hdf5\n",
            "dice_results_3D_valid.csv      wjhan_3Dmodel.hdf5\n",
            "dice_results_custom_train.csv  wjhan_custommodel.hdf5\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic2pcbAnxNON",
        "outputId": "136d7370-a036-4a92-9508-1f81b15ec6f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train mean\n",
            "0.9498334205781931\n",
            "0.9639075910933664\n",
            "0.9536712188215642\n",
            "train median\n",
            "0.9609836935997008\n",
            "0.9699203372001648\n",
            "0.9638468623161316\n",
            "train 25th\n",
            "0.9460278153419496\n",
            "0.9612881541252136\n",
            "0.9500337839126588\n",
            "train 75th\n",
            "0.9707959294319152\n",
            "0.9750203490257264\n",
            "0.9727936387062072\n",
            "valid mean\n",
            "0.9234169717924094\n",
            "0.9334891850565686\n",
            "0.930788650188917\n",
            "valid median\n",
            "0.956113874912262\n",
            "0.956473171710968\n",
            "0.9561198949813844\n",
            "valid 25th\n",
            "0.9116793870925904\n",
            "0.9358364343643188\n",
            "0.9258504509925842\n",
            "valid 75th\n",
            "0.9668260216712952\n",
            "0.96698796749115\n",
            "0.9693339467048644\n"
          ]
        }
      ],
      "source": [
        "customdf_train = pd.read_csv('dice_results_custom_train.csv')\n",
        "customdf_valid = pd.read_csv('dice_results_custom_valid.csv')\n",
        "\n",
        "threeddf_train = pd.read_csv('dice_results_3D_train.csv')\n",
        "threeddf_valid = pd.read_csv('dice_results_3D_valid.csv')\n",
        "\n",
        "twoddf_train = pd.read_csv('dice_results_2D_train.csv')\n",
        "twoddf_valid = pd.read_csv('dice_results_2D_valid.csv')\n",
        "\n",
        "print('train mean')\n",
        "\n",
        "print(customdf_train['Dice score'].mean())\n",
        "print(threeddf_train['Dice score'].mean())\n",
        "print(twoddf_train['Dice score'].mean())\n",
        "\n",
        "\n",
        "print('train median')\n",
        "\n",
        "print(customdf_train['Dice score'].median())\n",
        "print(threeddf_train['Dice score'].median())\n",
        "print(twoddf_train['Dice score'].median())\n",
        "\n",
        "\n",
        "print('train 25th')\n",
        "\n",
        "print(customdf_train['Dice score'].quantile(.25))\n",
        "print(threeddf_train['Dice score'].quantile(.25))\n",
        "print(twoddf_train['Dice score'].quantile(.25))\n",
        "\n",
        "\n",
        "print('train 75th')\n",
        "\n",
        "print(customdf_train['Dice score'].quantile(.75))\n",
        "print(threeddf_train['Dice score'].quantile(.75))\n",
        "print(twoddf_train['Dice score'].quantile(.75))\n",
        "\n",
        "\n",
        "print('valid mean')\n",
        "\n",
        "print(customdf_valid['Dice score'].mean())\n",
        "print(threeddf_valid['Dice score'].mean())\n",
        "print(twoddf_valid['Dice score'].mean())\n",
        "\n",
        "\n",
        "print('valid median')\n",
        "\n",
        "print(customdf_valid['Dice score'].median())\n",
        "print(threeddf_valid['Dice score'].median())\n",
        "print(twoddf_valid['Dice score'].median())\n",
        "\n",
        "\n",
        "print('valid 25th')\n",
        "print(customdf_valid['Dice score'].quantile(.25))\n",
        "print(threeddf_valid['Dice score'].quantile(.25))\n",
        "print(twoddf_valid['Dice score'].quantile(.25))\n",
        "\n",
        "\n",
        "print('valid 75th')\n",
        "print(customdf_valid['Dice score'].quantile(.75))\n",
        "print(threeddf_valid['Dice score'].quantile(.75))\n",
        "print(twoddf_valid['Dice score'].quantile(.75))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "vY4rtvIsfBqS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Create *.csv\n",
        "df_dict = {\n",
        "    'models'       : ['Custom', '3D', '2D'],\n",
        "    'mean_train'   : [0.9498334205781931, 0.9639075910933664, 0.9536712188215642], \n",
        "    'median_train' : [0.9609836935997008, 0.9699203372001648, 0.9638468623161316], \n",
        "    '25th_train'   : [0.9460278153419496, 0.9612881541252136, 0.9500337839126588],\n",
        "    '75th_train'   : [0.9707959294319152, 0.9750203490257264, 0.9727936387062072],\n",
        "    'mean_valid'   : [0.9234169717924094, 0.9334891850565686, 0.930788650188917],\n",
        "    'median_valid' : [0.956113874912262, 0.956473171710968, 0.9561198949813844], \n",
        "    '25th_valid'   : [0.9116793870925904, 0.9358364343643188, 0.9258504509925842],\n",
        "    '75th_valid'   : [0.9668260216712952, 0.96698796749115, 0.9693339467048644]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(df_dict)\n",
        "\n",
        "\n",
        "\n",
        "# --- Serialize *.csv\n",
        "df.to_csv('./wjhan_results.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaV-urr4fBqS"
      },
      "source": [
        "# Summary\n",
        "\n",
        "In addition to algorithm training as above, a 1-2 page write-up is required for this project. The goal is to *briefly* summarize algorithm design and key results. The write-up should be divided into three sections: methods; results; discussion. More detailed information and tips can be found here: https://github.com/peterchang77/dl_tutor/blob/master/cs190/spring_2021/notebooks/midterm/checklist.md.\n",
        "\n",
        "### Methods\n",
        "\n",
        "In this section, include details such as:\n",
        "\n",
        "* **Data**: How much data was used. How many cases were utilized for training and validation?\n",
        "* **Network design**: What are the different network architectures? How many layers and parameters? Were 2D or 3D operations used? Recall that the `model.summary(...)` can be used to provide key summary statistics for this purpose. If desired, feel free to include a model figure or diagram.\n",
        "* **Implementation**: How was training implemented. What are the key hyperparameters (e.g. learning rate, batch size, optimizer, etc)? How many training iterations were required for convergence? Did these hyperparameters change during the course of training?\n",
        "* **Statistics**: What statistics do you plan to use to evaluate model accuracy? \n",
        "\n",
        "### Results\n",
        "\n",
        "In this section, briefly summarize experimental results (a few sentences), and include the result table(s) as derived above.\n",
        "\n",
        "### Discussion\n",
        "\n",
        "Were the results expected or unexpected? What accounts for the differences in performance between the algorithms? How did you choose the network architecture implemented in your final model? Feel free to elaborate on any additional observations noted during the course of this expierment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEGoI0JBfBqS"
      },
      "source": [
        "# Submission\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMqoVbkUfBqS"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed the midterm assignment, download the necessary files from Google Colab and your Google Drive. As in prior assigments, be sure to prepare:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (results) spreadsheet: `[UCInetID]_results.csv` (compiled for all three parts)\n",
        "* final (trained) model: `[UCInetID]_model.hdf5` (three separate files for all three parts)\n",
        "\n",
        "In addition, submit the summary write-up as in any common document format (`.docx`, `.tex`, `.pdf`, etc):\n",
        "\n",
        "* final summary write-up: `[UCInetID]_summary.[docx|tex|pdf]`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadsheet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "wjhan_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
